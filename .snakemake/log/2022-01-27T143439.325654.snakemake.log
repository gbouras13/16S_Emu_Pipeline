Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 16
Rules claiming more threads will be scaled down.
Job stats:
job            count    min threads    max threads
-----------  -------  -------------  -------------
all                1              1              1
emu                3             16             16
get_db             1              1              1
krona              3              1              1
krona_input        3              1              1
read_count         3              1              1
total             14              1             16

Select jobs to execute...

[Thu Jan 27 14:34:41 2022]
rule emu:
    input: fastqs/porechopped/barcode03.fastq.gz
    output: emu_results/barcode03_rel-abundance-threshold-0.01.tsv
    jobid: 4
    wildcards: sample=barcode03
    threads: 16
    resources: tmpdir=/var/folders/2q/srp24kx525982p1wr0crt0tc0000gq/T

[Thu Jan 27 14:34:42 2022]
Error in rule emu:
    jobid: 4
    output: emu_results/barcode03_rel-abundance-threshold-0.01.tsv
    shell:
        
        emu abundance fastqs/porechopped/barcode03.fastq.gz --threads 16 --min-abundance 0.01 --db DB --output-dir emu_results --output-basename barcode03 --keep-files
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /Users/a1667917/Documents/Pipelines/16S_Emu_Pipeline/.snakemake/log/2022-01-27T143439.325654.snakemake.log
